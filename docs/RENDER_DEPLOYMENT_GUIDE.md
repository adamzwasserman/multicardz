# multicardz‚Ñ¢ Render Deployment Guide

## üöÄ Optimized for High-Performance Set Operations

This guide provides deployment configuration for achieving optimal performance of multicardz set operations on Render's infrastructure.

## üìä Performance by Render Plan

### **Starter Plan** ($7/month) - 0.5 vCPU, 512MB RAM
```
‚ùå Not recommended for production use
‚Ä¢ 1,000 cards: 20-50ms
‚Ä¢ 5,000 cards: 100-200ms
‚Ä¢ 10,000 cards: 300-600ms
‚Ä¢ 50,000 cards: 2-5 seconds
‚Ä¢ Memory limit prevents large datasets
```

### **Standard Plan** ($25/month) - 1 vCPU, 2GB RAM
```
‚ö†Ô∏è Suitable for small to medium datasets
‚Ä¢ 1,000 cards: 10-20ms ‚úÖ
‚Ä¢ 5,000 cards: 50-100ms ‚úÖ
‚Ä¢ 10,000 cards: 150-300ms
‚Ä¢ 50,000 cards: 1-3 seconds
‚Ä¢ 100,000 cards: 3-8 seconds
‚Ä¢ 1M cards: May timeout (30-60s)
```

### **Pro Plan** ($85/month) - 2 vCPUs, 4GB RAM
```
‚úÖ Recommended for production
‚Ä¢ 1,000 cards: 5-15ms ‚úÖ
‚Ä¢ 5,000 cards: 25-50ms ‚úÖ
‚Ä¢ 10,000 cards: 75-150ms ‚úÖ
‚Ä¢ 50,000 cards: 500ms-1.5s ‚úÖ
‚Ä¢ 100,000 cards: 1.5-4 seconds ‚úÖ
‚Ä¢ 1M cards: 15-30 seconds
```

### **Pro Plus Plan** ($185/month) - 4 vCPUs, 8GB RAM
```
üèÜ Optimal for large-scale operations
‚Ä¢ 1,000 cards: <10ms ‚úÖ
‚Ä¢ 5,000 cards: <25ms ‚úÖ
‚Ä¢ 10,000 cards: <50ms ‚úÖ
‚Ä¢ 50,000 cards: <300ms ‚úÖ
‚Ä¢ 100,000 cards: <1 second ‚úÖ
‚Ä¢ 1M cards: <10 seconds ‚úÖ
```

## üîß Deployment Configuration

### 1. **render.yaml Configuration**

```yaml
services:
  - type: web
    name: multicardz-web
    env: python
    plan: pro  # Minimum recommended
    buildCommand: |
      pip install --upgrade pip
      pip install -r requirements.txt
      python -m compileall .
    startCommand: |
      python -c "from render_performance_config import apply_render_optimizations; apply_render_optimizations()"
      gunicorn --workers 2 --threads 4 --timeout 120 app:app

    envVars:
      - key: PYTHONOPTIMIZE
        value: 2
      - key: PYTHONUNBUFFERED
        value: 1
      - key: MULTICARDZ_PERFORMANCE_MODE
        value: render
      - key: MULTICARDZ_MAX_CARDS
        value: 1000000

    healthCheckPath: /health
    numInstances: 1
```

### 2. **Requirements.txt**

```txt
# Core dependencies
pydantic>=2.0.0
numpy>=1.24.0
psutil>=5.9.0

# Web framework (adjust as needed)
fastapi>=0.104.0
uvicorn>=0.24.0
gunicorn>=21.2.0

# Optional performance dependencies
numba>=0.58.0  # JIT compilation for numerical operations
```

### 3. **Health Check Endpoint**

Add to your web application:

```python
from health_check import health_endpoint, performance_endpoint, quick_health

@app.get("/health")
def health():
    return quick_health()

@app.get("/health/detailed")
def health_detailed():
    return health_endpoint()

@app.get("/performance")
def performance():
    return performance_endpoint()
```

## ‚ö° Automatic Optimizations

The system automatically applies Render-specific optimizations:

### **Starter Plan Optimizations**
- Minimal caching (25 entries)
- Single-threaded processing
- Turbo mode for 50k+ cards
- Memory limits enforced

### **Standard Plan Optimizations**
- Moderate caching (100 entries)
- Single vCPU optimization
- Turbo mode for 75k+ cards
- 500k card limit

### **Pro Plan Optimizations**
- Full caching (200 entries)
- Parallel processing enabled
- Turbo mode for 100k+ cards
- 1M card limit

### **Pro Plus Optimizations**
- Maximum caching (500 entries)
- Full parallel processing
- Turbo mode for 50k+ cards
- 2M card limit

## üìà Performance Monitoring

### **Real-Time Monitoring**

```bash
# Check health
curl https://your-app.onrender.com/health

# Detailed performance report
curl https://your-app.onrender.com/performance

# Run benchmark manually
python health_check.py benchmark 10000
```

### **Key Metrics to Monitor**

1. **Memory Usage**: Should stay below 80%
2. **CPU Usage**: Spikes during large operations
3. **Response Times**: Track against targets
4. **Cache Hit Rate**: Should be >70% for repeated operations
5. **Error Rate**: Monitor for timeout errors

## üõ†Ô∏è Performance Tuning

### **Environment Variables**

```bash
# Performance mode
MULTICARDZ_PERFORMANCE_MODE=render

# Maximum cards per operation
MULTICARDZ_MAX_CARDS=1000000

# Cache settings
MULTICARDZ_CACHE_SIZE=200
MULTICARDZ_CACHE_TTL=3600

# Timeout settings
MULTICARDZ_TIMEOUT=120
```

### **Request Timeout Configuration**

For large operations, configure appropriate timeouts:

```python
# For Pro Plan
TIMEOUT_SETTINGS = {
    "1k": 1,      # 1 second
    "10k": 5,     # 5 seconds
    "100k": 30,   # 30 seconds
    "1M": 120     # 2 minutes
}

# For Pro Plus Plan
TIMEOUT_SETTINGS = {
    "1k": 1,      # 1 second
    "10k": 2,     # 2 seconds
    "100k": 10,   # 10 seconds
    "1M": 30      # 30 seconds
}
```

## üö® Troubleshooting

### **Common Issues**

#### **Memory Errors**
```
Solution: Upgrade to higher plan or reduce dataset size
Monitor: /health endpoint memory_percent
```

#### **Timeout Errors**
```
Solution: Increase timeout or optimize operations
Monitor: execution_time_ms in performance reports
```

#### **Poor Performance**
```
Solution: Check CPU usage and cache hit rates
Debug: Run performance benchmark and compare to targets
```

### **Debug Commands**

```bash
# Run performance benchmark
python health_check.py benchmark 100000

# Check Render configuration
python -c "from render_performance_config import render_config; print(render_config.plan_tier)"

# Test operation with debugging
python -c "
from apps.shared.services.set_operations_unified import apply_unified_operations
# Add your test code here
"
```

## üìã Deployment Checklist

- [ ] Set appropriate Render plan based on expected load
- [ ] Configure environment variables
- [ ] Set up health check endpoints
- [ ] Test performance benchmarks
- [ ] Configure monitoring and alerting
- [ ] Set appropriate timeouts
- [ ] Test with realistic dataset sizes
- [ ] Monitor memory and CPU usage
- [ ] Validate cache performance
- [ ] Test error handling and limits

## üéØ Plan Recommendations

### **Development/Testing**
- **Standard Plan**: Adequate for testing and small datasets

### **Production (Small Scale)**
- **Pro Plan**: Good balance of performance and cost
- **Expected**: <50ms for 10k cards, <5s for 100k cards

### **Production (Large Scale)**
- **Pro Plus Plan**: Required for sub-second 1M card operations
- **Expected**: <10ms for 10k cards, <10s for 1M cards

### **Enterprise Scale**
- **Pro Plus Plan + Multiple Instances**: Horizontal scaling
- **Expected**: Handle millions of operations per hour

## üîç Cost-Performance Analysis

| Plan | Monthly Cost | Max Recommended Cards | 1M Card Performance |
|------|-------------|---------------------|-------------------|
| Starter | $7 | 10,000 | Not suitable |
| Standard | $25 | 100,000 | 30-60 seconds |
| Pro | $85 | 1,000,000 | 15-30 seconds |
| Pro Plus | $185 | 2,000,000+ | <10 seconds ‚úÖ |

**Recommendation**: Pro Plus plan provides the best performance for the sub-second 1M card target.
